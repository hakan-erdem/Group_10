{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa1d47e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbaa419",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Solve the potential data leakage on the dataset="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc7afa8",
   "metadata": {},
   "source": [
    "# 1. Solving Potential Data Leakage on the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bedfbc",
   "metadata": {},
   "source": [
    "- I thought on the problem that state and parking_options features having high feature importances.\n",
    "- I noticed that I might have caused data leakage. Due to the fact that I fill the null values and encode the categorical features according to the target feature, this might be causing data leakage.\n",
    "- In order to solve this I will first split the train and test sets and find the mappings for null filling the null values and encoding categorical features from the train set. Then I will apply the same mappings for the test set, just like in scaling the dataset.\n",
    "- Therefore, I need to process the data again. However, I will skip the explanations this time until null value management and encoding categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d293db1",
   "metadata": {},
   "source": [
    "## 1.1 Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55f92b",
   "metadata": {},
   "source": [
    "### Utils for section 1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e446451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_iqr_and_fences(df, feature):\n",
    "    iqr = df[feature].quantile(0.75) - df[feature].quantile(0.25)\n",
    "    upper_fence = df[feature].quantile(0.75) + 1.5 * iqr\n",
    "    lower_fence = df[feature].quantile(0.25) - 1.5 * iqr\n",
    "    \n",
    "    print(f\"{feature} feature's IQR: {iqr}\")    \n",
    "    print(f\"Samples above with value {upper_fence} should be dropped\")\n",
    "    print(f\"Amount of outliers detected in upper region: {df[df[feature] > upper_fence].shape[0]}\\n\")\n",
    "    \n",
    "    print(f\"Samples below with value {lower_fence} should be dropped\")\n",
    "    print(f\"Amount of outliers detected in lower region: {df[df[feature] < lower_fence].shape[0]}\")\n",
    "    \n",
    "    return lower_fence, upper_fence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ff521",
   "metadata": {},
   "source": [
    "### 1.1.1 Parts that are not related with the leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eeb1f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"main_raw.csv\")\n",
    "\n",
    "# added parking_options feature here\n",
    "df = df.drop(columns=[\"id\", \"url\", \"region_url\", \"image_url\", \"parking_options\", \"region\"])\n",
    "df = df.drop_duplicates(keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d316f1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price feature's IQR: 645.0\n",
      "Samples above with value 2467.5 should be dropped\n",
      "Amount of outliers detected in upper region: 11038\n",
      "\n",
      "Samples below with value -112.5 should be dropped\n",
      "Amount of outliers detected in lower region: 0\n",
      "sqfeet feature's IQR: 398.0\n",
      "Samples above with value 1747.0 should be dropped\n",
      "Amount of outliers detected in upper region: 7100\n",
      "\n",
      "Samples below with value 155.0 should be dropped\n",
      "Amount of outliers detected in lower region: 473\n",
      "beds feature's IQR: 1.0\n",
      "Samples above with value 3.5 should be dropped\n",
      "Amount of outliers detected in upper region: 3706\n",
      "\n",
      "Samples below with value -0.5 should be dropped\n",
      "Amount of outliers detected in lower region: 0\n"
     ]
    }
   ],
   "source": [
    "# Outlier Management\n",
    "\n",
    "df = df[df.price >= 400]\n",
    "lower, upper = find_iqr_and_fences(df, \"price\")\n",
    "df = df[df.price <= upper]\n",
    "\n",
    "lower, upper = find_iqr_and_fences(df, \"sqfeet\")\n",
    "df = df[(lower <= df.sqfeet) & (df.sqfeet <= upper)]\n",
    "\n",
    "lower, upper = find_iqr_and_fences(df, \"beds\")\n",
    "df = df[(lower <= df.beds) & (df.beds <= 5)]\n",
    "\n",
    "df.baths = df.baths.apply(np.ceil).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fcb9be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some other parts\n",
    "\n",
    "df = df.dropna(subset=\"description\")\n",
    "df[\"lat\"].fillna(df[\"lat\"].mean(), inplace=True)\n",
    "df[\"long\"].fillna(df[\"long\"].mean(), inplace=True)\n",
    "df = df.dropna(subset=\"state\")\n",
    "\n",
    "df[\"pets_allowed\"] = df.cats_allowed | df.dogs_allowed\n",
    "df.drop(columns=[\"cats_allowed\",\"dogs_allowed\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2743a6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 195680/195680 [01:30<00:00, 2161.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# description column feature engineering\n",
    "\n",
    "count_dict = {}\n",
    "for row in tqdm(df.description):\n",
    "    words = row.lower().strip().split()\n",
    "    words = [re.sub(\"[^\\w\\s]\", \"\", w) for w in words]\n",
    "\n",
    "    for word in words:\n",
    "        if word in count_dict:\n",
    "            count_dict[word] += 1\n",
    "        else:\n",
    "            count_dict[word] = 1\n",
    "\n",
    "count_dict = dict(sorted(count_dict.items(), key=lambda x:x[1], reverse=True))\n",
    "count_dict\n",
    "\n",
    "df[\"has_pool\"] = df.description.str.lower().str.contains(\"pool|swim\").astype(int)\n",
    "df[\"has_sports\"] = df.description.str.contains(\"fitness|gym|basketball|spa|tennis\").astype(int)\n",
    "df[\"has_park\"] = df.description.str.lower().str.replace(\"parking\", \"\").str.contains(\"park|garden\").astype(int)\n",
    "df[\"has_shopping\"] = df.description.str.contains(\"mall|shop|market|grocery|store|downtown\").astype(int)\n",
    "df[\"has_transportation\"] = df.description.str.contains(\"transportation|airport|station|bus|train\").astype(int)\n",
    "\n",
    "df.drop(columns=[\"description\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03abd626",
   "metadata": {},
   "source": [
    "### 1.1.2 Parts that are related with the leakage (nulls and encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35ab8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I intentionally passed the X as df, because I need the target feature in the following parts\n",
    "train_set, test_set, _, _ = train_test_split(df, df[\"price\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d210c",
   "metadata": {},
   "source": [
    "### 1.1.2.1 null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a39d6df",
   "metadata": {},
   "source": [
    "- there are two features need to be handled here, laundry_options and parking_options. However, I decided to drop parking_options because its 40% null\n",
    "- dropping parking_options was done at the beginning of the dropping columns part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0724ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nulls_train(feature, train_set):\n",
    "    null_indexes = train_set[train_set[feature].isna()][[feature]].index\n",
    "    lookup = train_set[[\"price\", feature]].groupby(feature).mean().price\n",
    "    \n",
    "    print(lookup)\n",
    "\n",
    "    for idx in tqdm(null_indexes):\n",
    "        closest_label_idx = (lookup - train_set.loc[idx, \"price\"]).apply(abs).argmin()\n",
    "        train_set.loc[idx, feature] = lookup.index[closest_label_idx]\n",
    "        \n",
    "    return lookup\n",
    "        \n",
    "def fill_nulls_test(feature, test_set, lookup):\n",
    "    null_indexes = test_set[test_set[feature].isna()][[feature]].index\n",
    "    \n",
    "    print(lookup)\n",
    "\n",
    "    for idx in tqdm(null_indexes):\n",
    "        closest_label_idx = (lookup - test_set.loc[idx, \"price\"]).apply(abs).argmin()\n",
    "        test_set.loc[idx, feature] = lookup.index[closest_label_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed84e4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laundry_options\n",
      "laundry in bldg       1028.799666\n",
      "laundry on site       1062.515598\n",
      "no laundry on site     970.261558\n",
      "w/d hookups           1037.893169\n",
      "w/d in unit           1329.118266\n",
      "Name: price, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 35932/35932 [00:17<00:00, 2026.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laundry_options\n",
      "laundry in bldg       1028.799666\n",
      "laundry on site       1062.515598\n",
      "no laundry on site     970.261558\n",
      "w/d hookups           1037.893169\n",
      "w/d in unit           1329.118266\n",
      "Name: price, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8917/8917 [00:03<00:00, 2870.14it/s]\n"
     ]
    }
   ],
   "source": [
    "train_lookup = fill_nulls_train(\"laundry_options\", train_set)\n",
    "fill_nulls_test(\"laundry_options\", test_set, train_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bceda2",
   "metadata": {},
   "source": [
    "- notice that the test set is filled with the lookup table of train set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a7af5a",
   "metadata": {},
   "source": [
    "### 1.1.2.2 encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78b8c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encode_train(feature, train_set):\n",
    "    print(f\"\\nBEFORE:\\n{train_set[feature].value_counts()}\")\n",
    "    \n",
    "    # finding and ordering the categories of the feature according to the average price\n",
    "    # finally gathering the indexes for creating a mapper\n",
    "    ordered_labels = train_set[[feature,\"price\"]].groupby(feature).mean().sort_values(\"price\").index\n",
    "    \n",
    "    # creating a mapper to use it to map the values\n",
    "    mapper = {}\n",
    "    for idx, label in enumerate(ordered_labels):\n",
    "        mapper[label] = idx\n",
    "    \n",
    "    # mapping\n",
    "    train_set[feature] = train_set[feature].map(mapper)\n",
    "    \n",
    "    print(f\"\\nAFTER:\\n{train_set[feature].value_counts()}\")\n",
    "    \n",
    "    return mapper\n",
    "\n",
    "def ordinal_encode_test(feature, test_set, mapper):\n",
    "    print(f\"\\nBEFORE:\\n{test_set[feature].value_counts()}\")\n",
    "    \n",
    "    # mapping according to the mapper of the train set\n",
    "    test_set[feature] = test_set[feature].map(mapper)\n",
    "    \n",
    "    print(f\"\\nAFTER:\\n{test_set[feature].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "069f645b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEFORE:\n",
      "type\n",
      "apartment        133144\n",
      "house             10437\n",
      "townhouse          5438\n",
      "condo              2763\n",
      "duplex             2048\n",
      "manufactured       1696\n",
      "cottage/cabin       395\n",
      "loft                315\n",
      "flat                203\n",
      "in-law              104\n",
      "land                  1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AFTER:\n",
      "type\n",
      "5     133144\n",
      "2      10437\n",
      "6       5438\n",
      "9       2763\n",
      "3       2048\n",
      "1       1696\n",
      "4        395\n",
      "7        315\n",
      "10       203\n",
      "8        104\n",
      "0          1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "BEFORE:\n",
      "type\n",
      "apartment        33337\n",
      "house             2588\n",
      "townhouse         1341\n",
      "condo              672\n",
      "duplex             521\n",
      "manufactured       421\n",
      "cottage/cabin       91\n",
      "loft                76\n",
      "flat                61\n",
      "in-law              28\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AFTER:\n",
      "type\n",
      "5     33337\n",
      "2      2588\n",
      "6      1341\n",
      "9       672\n",
      "3       521\n",
      "1       421\n",
      "4        91\n",
      "7        76\n",
      "10       61\n",
      "8        28\n",
      "Name: count, dtype: int64\n",
      "\n",
      "BEFORE:\n",
      "laundry_options\n",
      "w/d in unit           67516\n",
      "w/d hookups           28742\n",
      "laundry on site       25327\n",
      "no laundry on site    17573\n",
      "laundry in bldg       17386\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AFTER:\n",
      "laundry_options\n",
      "4    67516\n",
      "2    28742\n",
      "3    25327\n",
      "0    17573\n",
      "1    17386\n",
      "Name: count, dtype: int64\n",
      "\n",
      "BEFORE:\n",
      "laundry_options\n",
      "w/d in unit           16981\n",
      "w/d hookups            7179\n",
      "laundry on site        6256\n",
      "no laundry on site     4377\n",
      "laundry in bldg        4343\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AFTER:\n",
      "laundry_options\n",
      "4    16981\n",
      "2     7179\n",
      "3     6256\n",
      "0     4377\n",
      "1     4343\n",
      "Name: count, dtype: int64\n",
      "\n",
      "BEFORE:\n",
      "state\n",
      "fl    20440\n",
      "ca    17011\n",
      "nc    10630\n",
      "mi     8565\n",
      "ga     7775\n",
      "co     7397\n",
      "ny     5923\n",
      "mn     5345\n",
      "md     5342\n",
      "il     5226\n",
      "ia     4797\n",
      "la     4414\n",
      "az     4022\n",
      "in     3992\n",
      "oh     3925\n",
      "al     3678\n",
      "ks     3302\n",
      "ky     2976\n",
      "nj     2864\n",
      "ms     2770\n",
      "ma     2732\n",
      "id     2644\n",
      "nd     2508\n",
      "ct     2316\n",
      "ar     1939\n",
      "ne     1802\n",
      "nm     1623\n",
      "dc     1542\n",
      "nv     1480\n",
      "de     1456\n",
      "ak     1442\n",
      "nh     1255\n",
      "mo     1191\n",
      "hi      995\n",
      "mt      901\n",
      "me      264\n",
      "ok       33\n",
      "or       27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AFTER:\n",
      "state\n",
      "25    20440\n",
      "35    17011\n",
      "17    10630\n",
      "16     8565\n",
      "14     7775\n",
      "30     7397\n",
      "24     5923\n",
      "22     5345\n",
      "29     5342\n",
      "9      5226\n",
      "8      4797\n",
      "11     4414\n",
      "18     4022\n",
      "4      3992\n",
      "10     3925\n",
      "7      3678\n",
      "2      3302\n",
      "5      2976\n",
      "34     2864\n",
      "3      2770\n",
      "32     2732\n",
      "20     2644\n",
      "15     2508\n",
      "27     2316\n",
      "6      1939\n",
      "13     1802\n",
      "12     1623\n",
      "36     1542\n",
      "23     1480\n",
      "26     1456\n",
      "21     1442\n",
      "33     1255\n",
      "1      1191\n",
      "37      995\n",
      "19      901\n",
      "28      264\n",
      "0        33\n",
      "31       27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "BEFORE:\n",
      "state\n",
      "fl    5090\n",
      "ca    4283\n",
      "nc    2698\n",
      "mi    2168\n",
      "ga    1987\n",
      "co    1837\n",
      "ny    1447\n",
      "il    1383\n",
      "mn    1334\n",
      "md    1315\n",
      "ia    1148\n",
      "la    1131\n",
      "az     994\n",
      "in     979\n",
      "oh     919\n",
      "al     918\n",
      "ks     843\n",
      "nj     727\n",
      "ms     720\n",
      "ky     692\n",
      "ma     677\n",
      "id     675\n",
      "nd     649\n",
      "ct     570\n",
      "ar     468\n",
      "ne     453\n",
      "dc     411\n",
      "nv     399\n",
      "nm     371\n",
      "ak     339\n",
      "de     338\n",
      "nh     314\n",
      "mo     295\n",
      "hi     247\n",
      "mt     227\n",
      "me      72\n",
      "or       9\n",
      "ok       9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AFTER:\n",
      "state\n",
      "25    5090\n",
      "35    4283\n",
      "17    2698\n",
      "16    2168\n",
      "14    1987\n",
      "30    1837\n",
      "24    1447\n",
      "9     1383\n",
      "22    1334\n",
      "29    1315\n",
      "8     1148\n",
      "11    1131\n",
      "18     994\n",
      "4      979\n",
      "10     919\n",
      "7      918\n",
      "2      843\n",
      "34     727\n",
      "3      720\n",
      "5      692\n",
      "32     677\n",
      "20     675\n",
      "15     649\n",
      "27     570\n",
      "6      468\n",
      "13     453\n",
      "36     411\n",
      "23     399\n",
      "12     371\n",
      "21     339\n",
      "26     338\n",
      "33     314\n",
      "1      295\n",
      "37     247\n",
      "19     227\n",
      "28      72\n",
      "31       9\n",
      "0        9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cat_cols = [\"type\", \"laundry_options\", \"state\"]\n",
    "\n",
    "for f in cat_cols:\n",
    "    mapper = ordinal_encode_train(f, train_set)\n",
    "    ordinal_encode_test(f, test_set, mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e8b5dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price                      0\n",
       "type                       0\n",
       "sqfeet                     0\n",
       "beds                       0\n",
       "baths                      0\n",
       "smoking_allowed            0\n",
       "wheelchair_access          0\n",
       "electric_vehicle_charge    0\n",
       "comes_furnished            0\n",
       "laundry_options            0\n",
       "lat                        0\n",
       "long                       0\n",
       "state                      0\n",
       "pets_allowed               0\n",
       "has_pool                   0\n",
       "has_sports                 0\n",
       "has_park                   0\n",
       "has_shopping               0\n",
       "has_transportation         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a6fe5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price                      0\n",
       "type                       0\n",
       "sqfeet                     0\n",
       "beds                       0\n",
       "baths                      0\n",
       "smoking_allowed            0\n",
       "wheelchair_access          0\n",
       "electric_vehicle_charge    0\n",
       "comes_furnished            0\n",
       "laundry_options            0\n",
       "lat                        0\n",
       "long                       0\n",
       "state                      0\n",
       "pets_allowed               0\n",
       "has_pool                   0\n",
       "has_sports                 0\n",
       "has_park                   0\n",
       "has_shopping               0\n",
       "has_transportation         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e1e22a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.reset_index().drop(columns=[\"index\"])\n",
    "test_set = test_set.reset_index().drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17b8b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv(\"main_ordinal_updated_train.csv\", index=False)\n",
    "test_set.to_csv(\"main_ordinal_updated_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90177f24",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
